{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ' if you want you'\n",
    "# sample = (\"if you want to build a ship, don't drum up people together to \"\n",
    "# \"collect wood and don't assign them tasks and work, but rather \"\n",
    "# \"teach them to long for the endless immensity of the sea.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char = list(set(sample))\n",
    "char2idx = {c: i for i, c in enumerate(idx2char)}\n",
    "\n",
    "# hyper parameter\n",
    "dic_size = len(char2idx)\n",
    "hidden_size = len(char2idx)\n",
    "num_classes = len(char2idx)\n",
    "batch_size = 1\n",
    "sequence_length = len(sample) - 1\n",
    "learning_rate = 0.1\n",
    "\n",
    "sample_idx = [char2idx[c] for c in sample]\n",
    "x_data = [sample_idx[:-1]]\n",
    "y_data = [sample_idx[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "    \n",
    "# RNN\n",
    "x_one_hot = tf.one_hot(X, num_classes)\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_size, state_is_tuple=True)\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "outputs, _states = tf.nn.dynamic_rnn(cell, x_one_hot, initial_state=initial_state, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FC\n",
    "X_for_fc = tf.reshape(outputs, [-1, hidden_size])\n",
    "outputs = tf.contrib.layers.fully_connected(X_for_fc, num_classes, activation_fn=None)\n",
    "\n",
    "outputs = tf.reshape(outputs, [batch_size, sequence_length, num_classes])\n",
    "\n",
    "weights = tf.ones([batch_size, sequence_length])\n",
    "# 원래는 outputs 를 logits 에 그대로 쓰는 거 아님\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(logits=outputs, targets=Y, weights=weights)\n",
    "loss = tf.reduce_mean(sequence_loss)\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "prediction = tf.argmax(outputs, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss: 3.2174144 Prediction:                                                                                                                                                                                    \n",
      "1 loss: 2.9646828 Prediction:                                                               o                             o                                                                                      \n",
      "2 loss: 2.936613 Prediction: n ttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
      "3 loss: 2.851164 Prediction:   t   tt t t  tt    t t e   t   t t    t  t      t     e  t  tt      tt   t t t   t t      t e        t t tt    t   t   e  t    et e     t    t   t e t       t         t  t e t   \n",
      "4 loss: 2.748186 Prediction:                                                        e                                     e                                     e                e                        e     \n",
      "5 loss: 2.6762292 Prediction:                                                        e             t                       e                                  e  e                e                        e     \n",
      "6 loss: 2.5651119 Prediction:   t    a   th t      st           t       t      th   he  th th    hhth       t     t      t e   h    ts  ta        t   e  th  hethe   h t    t   the t       t         a  the t   \n",
      "7 loss: 2.4314694 Prediction:   a   tosd th tu    tsts       d  t    t  t      th   he  ah th    hhhh   asd t  d  tss    t e  ahs   tsd to    a   a she  ah shethe  ah te d t   ahe h       t         a  ahe ae s\n",
      "8 loss: 2.2868576 Prediction:   a   tosd th tu    dsss    d  dd t    d  d      th   he  th th  e hhhh   tsd t  dd tsss  dd e  ahsss tsd do    t   a she  ah shethe  ah te d t   the t       t    d    a  ahe te s\n",
      "9 loss: 2.1379855 Prediction:   ao  tosd th tu    tstse   t  d  t    t  te   e th   he  th th ee hhho l tnd t  d  tss    the  thsss tsd to    tu  o she  th shethe  th te d t   the t   e   t         t  the te s\n",
      "10 loss: 2.0023625 Prediction:   oo  tondoto tu ld tstse   t  dd to   t  oe  le to   he  to thlee toao l tnd to dd tsssi  toe  tosssstss to    tu  oonhe  to shetoe  to te d to  the tod e sit    sii  t  aoe te s\n",
      "11 loss: 1.8206464 Prediction: p oo  wond to tuuld tssse   to dd touu wu ooo le to   oe  to tolee totoul tnd d ddd tsssi itoe  tosssitss too   tuu aunoe  to shetoe  to teld to  toe tnd dssit    sii  t  toe ti s\n",
      "12 loss: 1.6914748 Prediction: p oo  wood to tu l  tssse   to '  to   wp oeep e to e he  to tolee totoll tnd wo '  tssii  toe  tosssitsd woo   tu  ooooe  to shetoe  to tel' to  toe t d e iii    sii  t  aoe ti s\n",
      "13 loss: 1.5605395 Prediction: p you wond to tu le tssseg  to '  to   up oeeple to e he  th thlee totoul tnd to '  tnsig  toe  tosssitnd woo   tu  oonhe  th nhetoe  to tel' to  the tn' esiii    si o a  aoe ti n\n",
      "14 loss: 1.4052948 Prediction: p you uand to cu le tsshep, ton't tou  up ppeple to enhe  th thlee totou  tnd ton't tnsig  toe  tosssitnd woo   tuu aunhe  thcnh the  to ce ' to  the tnd essitm mnsimy a  ahe te n\n",
      "15 loss: 1.253478 Prediction: p you uand to cupld asship, ton't tou  up poople to ether to colee t aou  tnd don't tnsig  toe  tosss tnd woo , tuu auaher toanh the  to ce ' to  thertad essitmmmnssmy a  ahe tetn\n",
      "16 loss: 1.133591 Prediction: p you wand to bupld asship, lon't tou  up people to ether to bolle t wool and don't tnsig  toem tosss tnd wook, tuu auaher toanh them to beng to  thertad ess immmnssmy a  themtetn\n",
      "17 loss: 0.99894893 Prediction: p you tand to bupld anship, lon't tou  up peeple to ethec to bolle t wool and don't tnsig  toem tosks tnd wook, tup aunhem toanh them to beng to  the etd ess imeensimy yf themtetn\n",
      "18 loss: 0.8884861 Prediction: p you wand to bupld asship, lon't aaup up people t  ethe  to bolle t wool and don't ansign toem tosks ind wook, tup waaher toanh toem to beng tor the etd ess imeensigy yf themtetn\n",
      "19 loss: 0.77633476 Prediction: p you wand do build asship, don't aaup up people to ether to bolle t wool and don't ansign toem tosks and wook, bup aaaher toa.h toem to bong tor the etd ess immensigy of toemtea.\n",
      "20 loss: 0.66916776 Prediction: f you want to build asship, don't dau  up people to ether th bolle t woon and don't dssign toem tosks and work, but aacher thach them to bong for the etd ess immensity af themtea.\n",
      "21 loss: 0.56867766 Prediction: f you want to build anship, don't dou  up people torether to collect woon and don't dssign toem tosks and work, but aacher toach them to bong for the end ess immensity of themtea.\n",
      "22 loss: 0.46002486 Prediction: f you want to build anship, don't doum up people torether to collect wood and don't assign toem tosks and work, but oacher toach them to bong for the endless immensity of the tea.\n",
      "23 loss: 0.3762219 Prediction: f you want to build anship, don't drum up people thg them to collect wood and don't assign them tosks and work, but oather toach them to bong for the end ess immensity of the sea.\n",
      "24 loss: 0.33932123 Prediction: f you want to build a ship, don't aou  up peeple oooecher to collect woolland don't assign them tosks and work, but rather thrch ther to long for the endless immensity of the sea.\n",
      "25 loss: 0.36038926 Prediction: f you want to build a ship, don't aoum u  people together to collect wood and don't assign the  tosks and work, but aather thach them to long for the endless immensity of the sea.\n",
      "26 loss: 0.27132034 Prediction: f you want to build a ship, don't drum up poople together to collect wood and don't dssign them tosks and wook, but rather thach them to tong for the endless immensity of the sea.\n",
      "27 loss: 0.2324728 Prediction: f you want to build a ship, don't drum up people together to collect wood and don't dssign them tosks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "28 loss: 0.19017139 Prediction: f you want to build a ship, don't drum up people together to collect wood and don't assign them tosks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "29 loss: 0.16609503 Prediction: f you want to build a ship, don't drum up people together to collect wood and don't assign them tosks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "30 loss: 0.13848151 Prediction: f you want to build a ship, don't drum up people together to collect wood and don't assign them tosks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "31 loss: 0.116583936 Prediction: f you want to build a ship, don't drum up people together to collect wood and don't assign them tosks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "32 loss: 0.099372976 Prediction: f you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "33 loss: 0.0822385 Prediction: f you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "34 loss: 0.06590436 Prediction: f you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "35 loss: 0.057262477 Prediction: f you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "36 loss: 0.0489187 Prediction: f you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "37 loss: 0.0419588 Prediction: f you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "38 loss: 0.034715805 Prediction: f you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 loss: 0.02977195 Prediction: f you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "40 loss: 0.025292028 Prediction: f you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "41 loss: 0.021643547 Prediction: f you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "42 loss: 0.018302685 Prediction: f you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "43 loss: 0.016038684 Prediction: f you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "44 loss: 0.0142885605 Prediction: f you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "45 loss: 0.013046287 Prediction: f you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "46 loss: 0.0127647035 Prediction: f you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "47 loss: 0.0112972 Prediction: f you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "48 loss: 0.009977065 Prediction: f you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "49 loss: 0.009163299 Prediction: f you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(50):\n",
    "        l, _ = sess.run([loss, train], feed_dict={X:x_data, Y:y_data})\n",
    "        result = sess.run(prediction, feed_dict={X:x_data})\n",
    "        \n",
    "        result_str = [idx2char[c] for c in np.squeeze(result)]\n",
    "        \n",
    "        print(i, \"loss:\", l, \"Prediction:\", ''.join(result_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
